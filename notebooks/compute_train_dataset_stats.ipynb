{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08684af6",
   "metadata": {},
   "source": [
    "This notebook is a bit dirty, it's used to compute the stats of the training dataset.      \n",
    "Its output is meant to be used to create a new kaggle dataset.    \n",
    "It was initially meant to be a simple \"test bench\" of the datasets refacto.    \n",
    "But it ended up being a standalone notebook.    \n",
    "This is why there is unused torch dataset that is used just to get its stats instead of its actual elements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca108780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T16:26:59.654900Z",
     "iopub.status.busy": "2025-07-01T16:26:59.654490Z",
     "iopub.status.idle": "2025-07-01T16:26:59.664063Z",
     "shell.execute_reply": "2025-07-01T16:26:59.663052Z"
    },
    "papermill": {
     "duration": 0.015319,
     "end_time": "2025-07-01T16:26:59.665504",
     "exception": false,
     "start_time": "2025-07-01T16:26:59.650185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.py\n",
    "\n",
    "# dataset\n",
    "TEST_DATASET_HANDLE = \"egortrushin/open-wfi-test\"\n",
    "TRAIN_VALIDAION_DATASET_HANDLE = \"brendanartley/openfwi-preprocessed-72x72\"\n",
    "SAMPLES_PER_NPY_FILE = 500\n",
    "PIXEL_WISE_STD_EPSILON = 1e-2\n",
    "# model\n",
    "CHANNELS_DIMENSION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018eb65c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-01T16:26:59.671615Z",
     "iopub.status.busy": "2025-07-01T16:26:59.671273Z",
     "iopub.status.idle": "2025-07-01T16:27:08.683472Z",
     "shell.execute_reply": "2025-07-01T16:27:08.682259Z"
    },
    "papermill": {
     "duration": 9.016897,
     "end_time": "2025-07-01T16:27:08.685148",
     "exception": false,
     "start_time": "2025-07-01T16:26:59.668251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from os import listdir\n",
    "from pathlib import Path\n",
    "from os.path import join, exists, splitext\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import Tensor\n",
    "from rich.progress import track\n",
    "from kagglehub import dataset_download\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceeecdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T16:27:08.691571Z",
     "iopub.status.busy": "2025-07-01T16:27:08.691046Z",
     "shell.execute_reply": "2025-07-01T16:38:25.782731Z"
    },
    "papermill": {
     "duration": 802.409147,
     "end_time": "2025-07-01T16:40:31.096828",
     "exception": false,
     "start_time": "2025-07-01T16:27:08.687681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b6e8a62ef64db5860661e965cda0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cffba5a78684161a5dea55d0085218a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d0e809b94a4c55bfe535c45a9b4873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e83db06fc3c4f66b19179c646e37f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75093a34b7c4e7d9f0d010acdb01892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See kaggle preprocessed train and validation datasets page: https://www.kaggle.com/datasets/brendanartley/openfwi-preprocessed-72x72\n",
    "# See kaggle competition page: https://www.kaggle.com/competitions/waveform-inversion\n",
    "# See preprocessed test dataset: https://www.kaggle.com/datasets/egortrushin/open-wfi-test\n",
    "import json\n",
    "from os import listdir\n",
    "from pathlib import Path\n",
    "from os.path import join, exists, splitext\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import Tensor\n",
    "from rich.progress import track\n",
    "from kagglehub import dataset_download\n",
    "\n",
    "from config import *\n",
    "\n",
    "\n",
    "_stats_type = dict[str, dict[str, dict[str, Tensor]]]\n",
    "\n",
    "class TrainValidationPreprocessedOpenFWI(torch.utils.data.Dataset):\n",
    "    def __init__(self, split:str=\"train\", nb_files=None):\n",
    "        super().__init__()\n",
    "        self.x, self.y = _load_dataset_tensors(split, nb_files)\n",
    "        self.stats = _get_train_stats(split, self.x, self.y)\n",
    "\n",
    "    def __getitem__(self, idx) -> torch.Tensor:\n",
    "        list_idx = idx // SAMPLES_PER_NPY_FILE\n",
    "        tensor_idx = idx % SAMPLES_PER_NPY_FILE\n",
    "        return (\n",
    "            self.x[list_idx][tensor_idx],\n",
    "            self.y[list_idx][tensor_idx],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x) * SAMPLES_PER_NPY_FILE\n",
    "\n",
    "def _get_train_stats(split:str, x:list[Tensor]=None, y:list[Tensor]=None) -> _stats_type:\n",
    "    stats_file_path = _get_dataset_stats_file_path(split)\n",
    "    if not exists(stats_file_path):\n",
    "        if x is None or y is None:\n",
    "            x, y = _load_dataset_tensors(\"train\")\n",
    "        stats = {\n",
    "            \"pixel_wise_stats\": {\n",
    "                \"x\": _compute_pixel_wise_welford_mean_std(x),\n",
    "                \"y\": _compute_pixel_wise_welford_mean_std(y),\n",
    "            },\n",
    "            \"pixel_agnostic_stats\": {\n",
    "                \"x\": _compute_pixel_agnostic_welford_mean_std(x),\n",
    "                \"y\": _compute_pixel_agnostic_welford_mean_std(y),\n",
    "            }\n",
    "        }\n",
    "        _save_stats_to_json(stats, stats_file_path)\n",
    "        return stats\n",
    "    else:\n",
    "        return load_stats_from_json(stats_file_path)\n",
    "\n",
    "def _save_stats_to_json(stats: _stats_type, filepath: str):\n",
    "    # Convert tensors to nested lists for JSON compatibility\n",
    "    serializable_stats = {\n",
    "        \"pixel_wise_stats\": {\n",
    "            \"x\": {key: value.tolist() for key, value in stats[\"pixel_wise_stats\"][\"x\"].items()},\n",
    "            \"y\": {key: value.tolist() for key, value in stats[\"pixel_wise_stats\"][\"y\"].items()},\n",
    "        },\n",
    "        \"pixel_agnostic_stats\": stats[\"pixel_agnostic_stats\"],\n",
    "    }\n",
    "    with open(filepath, \"w\") as fp:\n",
    "        json.dump(serializable_stats, fp, indent=1)\n",
    "\n",
    "def load_stats_from_json(filepath: str) -> _stats_type:\n",
    "    with open(filepath, \"r\") as fp:\n",
    "        serialized_stats = json.load(fp)\n",
    "    # Convert lists back to tensors\n",
    "    return {\n",
    "        \"pixel_wise_stats\": {\n",
    "            \"x\": {key: torch.tensor(value) for key, value in serialized_stats[\"pixel_wise_stats\"][\"x\"].items()},\n",
    "            \"y\": {key: torch.tensor(value) for key, value in serialized_stats[\"pixel_wise_stats\"][\"y\"].items()},\n",
    "        },\n",
    "        \"pixel_agnostic_stats\": serialized_stats[\"pixel_agnostic_stats\"],\n",
    "    }\n",
    "\n",
    "def _load_dataset_tensors(split:str, nb_files=None) -> tuple[Tensor, Tensor]:\n",
    "    dataset_path = dataset_download(TRAIN_VALIDAION_DATASET_HANDLE)\n",
    "    # column \"fold\" is equal to -100 for training and 0 for validation see kaggle dataset description\n",
    "    if split == \"train\":\n",
    "        fold_nb = -100 \n",
    "    elif split == \"validation\":\n",
    "        fold_nb = 0\n",
    "    else:\n",
    "        raise NotImplementedError(f'{split} is not a valid split, either use \"train\" or \"validation\"')\n",
    "    meta_df = (\n",
    "        pd.read_csv(join(dataset_path, \"folds.csv\"))\n",
    "        .query(f\"fold == {fold_nb}\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    nb_files = nb_files if nb_files else len(meta_df)\n",
    "    tensors_it = lambda path, files_group: track(meta_df.loc[:nb_files, path], files_group)\n",
    "    x = [_load_npy_file_as_tensor(dataset_path, f_path) for f_path in tensors_it(\"data_fpath\", \"loading inputs\")]\n",
    "    y = [_load_npy_file_as_tensor(dataset_path, f_path) for f_path in tensors_it(\"label_fpath\", \"loading outputs\")]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def _load_npy_file_as_tensor(dataset_path:str, path_in_dataset: str) -> torch.Tensor:\n",
    "    path = join(dataset_path, 'openfwi_72x72', path_in_dataset)\n",
    "    return torch.from_numpy(np.load(path))\n",
    "\n",
    "def _get_dataset_stats_file_path(split:str) -> Path:\n",
    "    return f\"dataset_stats_{split}.json\"\n",
    "    # return (\n",
    "    #     Path(__file__)\n",
    "    #     .absolute()\n",
    "    #     .parent\n",
    "    #     .joinpath(f\"dataset_stats_{split}.json\")\n",
    "    # )\n",
    "\n",
    "def _compute_pixel_agnostic_welford_mean_std(batches_list: list[Tensor]) -> dict[str, Tensor]:\n",
    "    count = 0\n",
    "    mean = torch.zeros(1, dtype=torch.float64)\n",
    "    M2 = torch.zeros(1, dtype=torch.float64)\n",
    "\n",
    "    for tensor in track(batches_list, description=\"Computing dataset stats\"):\n",
    "        x = tensor.view(-1).to(torch.float64)\n",
    "        batch_count = x.numel()\n",
    "        batch_mean = x.mean()\n",
    "        batch_M2 = ((x - batch_mean) ** 2).sum()\n",
    "\n",
    "        delta = batch_mean - mean\n",
    "        total_count = count + batch_count\n",
    "\n",
    "        mean += delta * batch_count / total_count\n",
    "        M2 += batch_M2 + delta.pow(2) * count * batch_count / total_count\n",
    "        count = total_count\n",
    "\n",
    "    variance = M2 / count\n",
    "    std = variance.sqrt().item()\n",
    "    return {\n",
    "        \"mean\": mean.item(),\n",
    "        \"std\": std,\n",
    "    }\n",
    "\n",
    "def _compute_pixel_wise_welford_mean_std(batches_list: list[Tensor]) -> dict[str, Tensor]:\n",
    "    first = next(iter(batches_list))\n",
    "    mean = torch.zeros_like(first[0], dtype=torch.float64)\n",
    "    M2 = torch.zeros_like(first[0], dtype=torch.float64)\n",
    "    count = 0\n",
    "\n",
    "    # Re-inject the first batch\n",
    "    batches_list = [first] + list(batches_list)\n",
    "\n",
    "    for batch in track(batches_list, description=\"Computing pixel-wise stats\"):\n",
    "        batch = batch.to(torch.float64)  # shape: (N, C, H, W)\n",
    "        batch_count = batch.shape[0]\n",
    "\n",
    "        batch_mean = batch.mean(dim=0)  # shape: (C, H, W)\n",
    "        batch_M2 = ((batch - batch_mean)**2).sum(dim=0)  # shape: (C, H, W)\n",
    "\n",
    "        delta = batch_mean - mean\n",
    "        total_count = count + batch_count\n",
    "\n",
    "        mean += delta * batch_count / total_count\n",
    "        M2 += batch_M2 + delta.pow(2) * count * batch_count / total_count\n",
    "\n",
    "        count = total_count\n",
    "\n",
    "    variance = M2 / count\n",
    "    # Ensure that there are no zeros in the std \n",
    "    std = variance.sqrt()\n",
    "    # std = torch.clamp(variance.sqrt(), min=PIXEL_WISE_STD_EPSILON)\n",
    "\n",
    "    return {\n",
    "        \"mean\": mean.float(),\n",
    "        \"std\": std.float()\n",
    "    }\n",
    "\n",
    "def _check_dataset_shape(split:str):\n",
    "    dataset = TrainValidationPreprocessedOpenFWI(split)\n",
    "    print(\"split:\", split)\n",
    "    print(dataset)\n",
    "    print(\"len:\", len(dataset))\n",
    "    def test_sample(idx:int):\n",
    "        x, y = dataset[0]\n",
    "        print(f\"x {idx} data type:\", type(x))\n",
    "        print(f\"x {idx} shape:\", x.shape)\n",
    "        print(f\"y {idx} data type:\", type(y))\n",
    "        print(f\"y {idx} shape:\", y.shape)\n",
    "\n",
    "    test_sample(0)\n",
    "    test_sample(100)\n",
    "    test_sample(len(dataset) - 1)\n",
    "    print(\"stats:\", dataset.stats)\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "# if __name__ == \"__main__\":  \n",
    "_check_dataset_shape(\"train\")\n",
    "_check_dataset_shape(\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28af3ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T16:20:56.154284Z",
     "iopub.status.busy": "2025-07-01T16:20:56.154024Z",
     "iopub.status.idle": "2025-07-01T16:23:54.853666Z",
     "shell.execute_reply": "2025-07-01T16:23:54.852844Z",
     "shell.execute_reply.started": "2025-07-01T16:20:56.154261Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify loading\n",
    "train_dataset = TrainValidationPreprocessedOpenFWI(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd2f19f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T16:26:34.445575Z",
     "iopub.status.busy": "2025-07-01T16:26:34.445099Z",
     "iopub.status.idle": "2025-07-01T16:26:34.452324Z",
     "shell.execute_reply": "2025-07-01T16:26:34.451499Z",
     "shell.execute_reply.started": "2025-07-01T16:26:34.445547Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset.stats[\"pixel_wise_stats\"][\"x\"][\"pxiel_wise_std\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646b856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T16:23:54.856599Z",
     "iopub.status.busy": "2025-07-01T16:23:54.856313Z",
     "iopub.status.idle": "2025-07-01T16:23:54.862308Z",
     "shell.execute_reply": "2025-07-01T16:23:54.860884Z",
     "shell.execute_reply.started": "2025-07-01T16:23:54.856578Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.stats[\"pixel_wise_stats\"][\"x\"]: #[\"std\"]\n",
    "    print(type(x))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7377931,
     "sourceId": 12038896,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 819.265292,
   "end_time": "2025-07-01T16:40:33.719635",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-01T16:26:54.454343",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
